{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install rouge_score nltk absl-py transformers evaluate sentencepiece\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debolina\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"madhavappaneni/t5-small-chit-chat\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, use_auth_token=\"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\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, use_auth_token=\"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\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a philanthropist. I don't know what you're talking about.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_response(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    outputs = model.generate(input_ids, max_length=30,\n",
    "                             do_sample=True, num_beams=5, no_repeat_ngram_size=2)\n",
    "    generated_text = tokenizer.decode(\n",
    "        outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "generate_response(\"How are you?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6662, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_pickle('./datasets/test.pkl')\n",
    "\n",
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm not a big fan of that, but I don't know how to do it.\", \"Well I'm going back home tonight! I just want to go to church in about 20mins!\", \"I'm up to you! What's yours?\", 'Nice!']\n",
      "['I am doing really well thanks for asking Are you just relaxing or doing anything fun today?', 'Oh that is exciting! Yeah real quick then BYU did this so they can get conversation data to help improve AI units to be more capable of conversation Rather than just one party talking the whole time', 'Yeah its pretty cool I am just spending the next few hours relaxing', 'Yeah It is always nice to take a break I dont really ever take enough']\n"
     ]
    }
   ],
   "source": [
    "reference_sentences = []\n",
    "generated_sentences = []\n",
    "start = 1\n",
    "end = 5\n",
    "for index, row in test_df[start:end].iterrows():\n",
    "    input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "    generated_sentences.append(generate_response(input_text))\n",
    "    reference_sentences.append(label)\n",
    "\n",
    "print(generated_sentences)\n",
    "print(reference_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in range(67):\n",
    "    start_index = batch * 100\n",
    "    end_index = min(start_index + 100, 6662)\n",
    "    batch_data = test_df[start_index:end_index]\n",
    "    reference_sentences = []\n",
    "    generated_sentences = []\n",
    "    for index, row in batch_data.iterrows():\n",
    "        input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "        generated_sentences.append(generate_response(input_text))\n",
    "        reference_sentences.append(label)\n",
    "        df = pd.DataFrame({'reference_sentences': reference_sentences,\n",
    "                           'generated_sentences': generated_sentences})\n",
    "        df.to_pickle('./files/ref_gen_'+str(start_index)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_batches = int(len(test_df) / batch_size)\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    start_index = batch * batch_size\n",
    "    end_index = min(start_index + batch_size, len(test_df))\n",
    "    batch_data = test_df[start_index:end_index]\n",
    "    reference_sentences = []\n",
    "    generated_sentences = []\n",
    "    for index, row in batch_data.iterrows():\n",
    "        input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "        generated_sentences.append(generate_response(input_text))\n",
    "        reference_sentences.append(label)\n",
    "    df = pd.DataFrame({'reference_sentences': reference_sentences,\n",
    "                       'generated_sentences': generated_sentences})\n",
    "    df.to_pickle(f'./files/ref_gen_{start_index}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "df_list = []\n",
    "\n",
    "directory = './files/'\n",
    "\n",
    "# Loop through all the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.pkl'):\n",
    "        # Read the file as a DataFrame and append to the list\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df_list.append(pd.read_pickle(filepath))\n",
    "\n",
    "# Concatenate all the DataFrames in the list into a single DataFrame\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.shape\n",
    "merged_df.to_pickle('./files/ref_gen_master.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_sentences</th>\n",
       "      <th>generated_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice! So you are planning on going to the part...</td>\n",
       "      <td>I'm glad you have a good day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haha, maybe you can find a girlfriend there. W...</td>\n",
       "      <td>Ya, it will be fun to meet up with all the peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What if it's a dude. I think what we could hav...</td>\n",
       "      <td>Haha yeah I think that would be a lot of fun. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>try it. It would be very casual, and she would...</td>\n",
       "      <td>I dont know what happened on the test. I feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As for the sixty eight, welcome to all of my c...</td>\n",
       "      <td>I asked her if she wanted to, but she was a girl.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 reference_sentences  \\\n",
       "0  Nice! So you are planning on going to the part...   \n",
       "1  Haha, maybe you can find a girlfriend there. W...   \n",
       "2  What if it's a dude. I think what we could hav...   \n",
       "3  try it. It would be very casual, and she would...   \n",
       "4  As for the sixty eight, welcome to all of my c...   \n",
       "\n",
       "                                 generated_sentences  \n",
       "0                      I'm glad you have a good day!  \n",
       "1  Ya, it will be fun to meet up with all the peo...  \n",
       "2  Haha yeah I think that would be a lot of fun. ...  \n",
       "3  I dont know what happened on the test. I feel ...  \n",
       "4  I asked her if she wanted to, but she was a girl.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_pickle('./files/ref_gen_master.pkl')\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242, 5242)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_sentences = list(merged_df['reference_sentences'])\n",
    "generated_sentences = list(merged_df['generated_sentences'])\n",
    "len(reference_sentences), len(generated_sentences)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLEU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00425577823639605"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\", module_type=\"metric\")\n",
    "results = bleu.compute(predictions=generated_sentences,\n",
    "                       references=reference_sentences)\n",
    "\n",
    "results['bleu']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLEURT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No checkpoint specified, defaulting to BLEURT-tiny.\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Debolina\\AppData\\Roaming\\Python\\Python311\\site-packages\\bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "-1.1293769249652053\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "scorer = score.BleurtScorer()\n",
    "scores = scorer.score(references=reference_sentences, candidates=generated_sentences)\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "precision, recall, f1 = score(\n",
    "    generated_sentences, reference_sentences, lang='en', verbose=False)\n",
    "\n",
    "print(f\"BERT score (F1): {f1.mean().item():.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROUGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "rouge_score = rouge.compute(\n",
    "    predictions=generated_sentences, references=reference_sentences)\n",
    "rouge_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# perplexity_results = perplexity.compute(\n",
    "#     predictions=generated_sentences, model_id='gpt2')\n",
    "# print(f\"Perplexity score: {perplexity_results['mean_perplexity']}\")\n",
    "\n",
    "# TODO:\n",
    "# This code takes a lot of time to run as it compares with GPT2 response. Perplexity can also be calculated from loss. Check that possibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No checkpoint specified, defaulting to BLEURT-tiny.\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Debolina\\AppData\\Roaming\\Python\\Python311\\site-packages\\bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reference_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m checkpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbleurt/BLEURT-20\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m scorer \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mBleurtScorer()\n\u001b[1;32m----> 6\u001b[0m scores \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39mscore(references\u001b[39m=\u001b[39mreference_sentences, candidates\u001b[39m=\u001b[39mgenerated_sentences)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(scores)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reference_sentences' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip .\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
